{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Interactive time-series visualisation of MONROE data\n",
    "\n",
    "## Features\n",
    "\n",
    "This notebook enables on-demand visualisation of time series data collected with MONROE platform. It provides the following features:\n",
    "* Fast visualisation of multiple parameters of data collected on MONROE nodes along the time dimension.\n",
    "* Adaptive granularity, where the data resolution is adjusted for maximum performance depending on the interactive visual analysis zoom level.\n",
    "* Selection and on-disk storage of visualised data for further analysis in Orange data mining toolbox. \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Database access\n",
    "Cassandra DB used for the central MONROE data repository is a no-SQL database inappropriate for time-series data mining. Instead, this notebook requires that the data is stored in an Influx DB accessible from the machine where this script is run. Influx DB is a database that __[performs up to 168 times faster for certain queries than Cassandra DB](https://www.influxdata.com/blog/influxdb-vs-cassandra-time-series/)__. To create a replica of MONROE data on your local Influx DB: \n",
    "> 1) Create recipes for loading and naming MONROE data tables and their attributes that you plan to have in your local database. __[Example recipes](https://github.com/ivek1312/ricercando/tree/master/scripts/recipes)__.\n",
    "\n",
    "> 2) Download __[MONROE daily dump CSV files](https://www.monroe-system.eu/user/dailyDumps/)__ of tables for which the recepies are present and for dates for which you would like to have data in your local database.\n",
    "\n",
    "> 3) Run cassandra_dump_to_line_protocol.sh as __[per instructions](https://github.com/ivek1312/ricercando/tree/master/scripts)__.\n",
    "\n",
    "### Python packages\n",
    "The notebook requires the following Python packages:\n",
    "* **ricercando** - this package is bundled in __[RICERCANDO repository](https://github.com/ivek1312/ricercando)__ and can be installed with ```pip install -e .\"``` ran in the repository's root directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis flow\n",
    "Please run the following cells one after another, starting with the pre-initialisation cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set to database IP. This must be reachable from the machine where this script is ran. \n",
    "# DB_IP='192.168.27.75'\n",
    "DB_IP='localhost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load with these parameters\n",
    "#jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000\n",
    "\n",
    "import holoviews as hv\n",
    "import param, paramnb\n",
    "import pandas as pd\n",
    "from colorcet import cm #pip install colorcet\n",
    "from holoviews.streams import RangeXY, RangeX\n",
    "import numpy as np\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "import time, os\n",
    "\n",
    "os.environ['TZ'] = 'UTC'\n",
    "time.tzset()\n",
    "\n",
    "#https://stackoverflow.com/questions/41675041/bokeh-time-series-plot-annotation-is-off-by-1-hour/41698735\n",
    "#https://github.com/bokeh/bokeh/issues/5499\n",
    "#https://github.com/bokeh/bokeh/issues/1135\n",
    "#https://github.com/bokeh/bokeh/issues/729\n",
    "#https://github.com/bokeh/bokeh/issues/1103\n",
    "\n",
    "\n",
    "\n",
    "from holoviews.operation.timeseries import rolling, rolling_outlier_std\n",
    "\n",
    "hv.notebook_extension('bokeh', width=100)\n",
    "\n",
    "from ricercando import set_connection_params, all_tables, all_nodes, getdf, tables_for_node, nodes_for_table \n",
    "from ricercando.db import _CATEGORICAL_COLUMNS\n",
    "set_connection_params(host=DB_IP)\n",
    "#set_connection_params(host='localhost')\n",
    "\n",
    "\n",
    "rtt_opts= {'Points':{'style':dict(cmap='Set3', size=2), 'plot':dict( color_index='Message', width=1400, height=400, colorbar=True, tools=['hover']) }}\n",
    "spikes_colors = {'Scheduling.Task.Started':'green', 'Scheduling.Task.Stopped':'red', 'Scheduling.Task.Deploying':'orange', 'Scheduling.Task.Deployed':'blues'}\n",
    "spike_opts={'Spikes':{'style':dict( line_width=2, color=hv.Palette('Set3')) }}\n",
    "\n",
    "\n",
    "\n",
    "sec_res = np.timedelta64(2*60,'m')\n",
    "min_res = np.timedelta64(1*24*60,'m')\n",
    "day_res = np.timedelta64(3*24*60,'m')\n",
    "\n",
    "\n",
    "#data type, if df doesnt coontain these valuse, fill them with appropriate NA values => 'None' if categorical, zero if continous\n",
    "values = {}\n",
    "categorical = list(_CATEGORICAL_COLUMNS)\n",
    "\n",
    "continous = ['Altitude', 'Latitude', 'Longitude', 'SatelliteCount', 'Speed', 'RTT', 'BootCounter', 'CPU_Apps', 'CPU_User', 'CumUptime', 'Swap', \n",
    "             'Uptime', 'RSCP','RSRP','RSRQ','RSSI', 'Temperature', 'IOWait', \n",
    "             'TCPCbytesAll','TCPSbytesAll','TCPDuration','TCPCRTTAVG','TCPCRTTSTD','TCPCPktsRetx','TCPCPktsOOO','TCPSPktsRetx','TCPSPktsOOO',\n",
    "            'Download','Upload','RTTClient','RTTServer','Status'\n",
    "            'UDPCbytesAll','UDPSbytesAll','UDPCDurat','UDPSDurat', 'TCPGoodPutUpload', 'TCPGoodPutDownload', 'UDPGoodPutUpload', 'UDPGoodPutDownload']\n",
    "\n",
    "for val in categorical:\n",
    "    values[val]='None'\n",
    "    \n",
    "for val in continous:\n",
    "    values[val]=0\n",
    "\n",
    "#all tables from dataframe\n",
    "tables = 'ping gps modem event sensor nettest tcpcomplete udpcomplete'\n",
    "\n",
    "#hv needs fixed number of overlays, layouts at zoom level... when spikes are empty nothing is shown. Lets workaround this by creating dummy spikes on center of x_range with length 0\n",
    "def dummy_spikes(x_range:None, Day, Month, Year):\n",
    "    if x_range is None:\n",
    "        center = (np.datetime64('{0}-{1}-{2} 00:00:00'.format(Year, Month, Day)))+np.timedelta64(12*60,'m')\n",
    "    else:\n",
    "        center = (x_range[1]-x_range[0])/2+x_range[0]\n",
    "    ds = hv.Dataset(( [center, center,center,center], ['Scheduling.Task.Started', 'Scheduling.Task.Stopped', 'Scheduling.Task.Deploying', 'Scheduling.Task.Deployed'] ), kdims=['Date', 'EventType'])\n",
    "    spike_opts['Spikes']['plot']=dict(spike_length=0)\n",
    "         \n",
    "    return ds.to(hv.Spikes).overlay().opts(spike_opts)\n",
    "\n",
    "def load_data(x_range, Node, Day, Month, Year, Coloring, Colormap, Y='RTT', **kwargs):\n",
    "    if x_range is not None:\n",
    "\n",
    "        t_delta = (x_range[1]-x_range[0])\n",
    "        if t_delta<=sec_res: #we can show 6h of data in 1s resolution with no slowdown\n",
    "            freq='10ms'\n",
    "        elif t_delta<=min_res: #1 day\n",
    "            freq='1m'\n",
    "        else:\n",
    "            freq='30m'\n",
    "            \n",
    "        df = getdf(tables, nodeid=Node, start_time=x_range[0] , end_time=x_range[1], freq=freq, tolerance=pd.Timedelta(seconds=600))\n",
    "        events = getdf('event', nodeid=Node, start_time=x_range[0], end_time=x_range[1], freq='10ms')       \n",
    "\n",
    "\n",
    "        \n",
    "    else:\n",
    "        df = getdf(tables, nodeid=Node, start_time='{0}-{1}-{2} 00:00:00'.format(Year, Month, Day), end_time='{0}-{1}-{2} 23:59:59'.format(Year, Month, Day), freq='1m', limit=200000, tolerance=pd.Timedelta(seconds=600))\n",
    "        events = getdf('event', nodeid=Node, start_time='{0}-{1}-{2} 00:00:00'.format(Year, Month, Day), end_time='{0}-{1}-{2} 23:59:59'.format(Year, Month, Day), freq='10ms')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #we must return something\n",
    "    if df.empty:\n",
    "        return    hv.Layout([hv.Points(pd.DataFrame(columns=['Date',Y]), kdims=['Date', Y],vdims=[]).opts(rtt_opts)  ]).cols(1)\n",
    "#     df['Date'] =  df.index.to_datetime() #doesnt work with pandas 23\n",
    "    df['Date'] =  pd.to_datetime(df.index)\n",
    "    \n",
    "\n",
    "    iccids = sorted(df.Iccid.unique().dropna().sort_values())\n",
    "\n",
    "    for val in categorical: #categorical data have nan and can't be shown if nan is not set to some new categirical value=>'None'\n",
    "        if val in df.columns:\n",
    "            df[val] =df[val].cat.add_categories(\"None\")\n",
    "        else: df[val] = np.nan\n",
    "\n",
    "    for val in continous:\n",
    "        if val not in df.columns:\n",
    "            df[val] = np.nan\n",
    "\n",
    "    #replace categorical nans with 'None' so it can be shown on plot, else error occurs => float to string exception\n",
    "    #replace continous nans with zeroes because\n",
    "    df=df.fillna(value=values)\n",
    "\n",
    "\n",
    "    rtt_opts['Points']['plot']['color_index']=Coloring\n",
    "\n",
    "    rtt_opts['Points']['style']['cmap']=Colormap\n",
    "\n",
    "    table = [ hv.Points(df[df.Iccid==iccid], kdims=['Date', Y], vdims=categorical+continous, label=iccid).opts(rtt_opts ) for iccid in iccids]\n",
    "\n",
    "    if not events.empty and 'EventType' in events.columns:\n",
    "        events=events[events['EventType'].str.contains('Scheduling')]\n",
    "        if not events.empty:\n",
    "            events['Date'] = pd.to_datetime(events.index)\n",
    "            ds = hv.Dataset((events.Date, events.EventType), kdims=['Date', 'EventType'])\n",
    "                    \n",
    "            max = df[Y].max()\n",
    "            min = df[Y].min()\n",
    "            length= abs(max-min)\n",
    "            \n",
    "            spike_opts['Spikes']['plot']=dict(spike_length=length, position=min)            \n",
    "            overlay = ds.to(hv.Spikes).overlay().opts(spike_opts)\n",
    "            table = [(plot*overlay).relabel(iccid) for plot,iccid in zip(table,iccids)]    \n",
    "             \n",
    "\n",
    "        else:\n",
    "            overlay = dummy_spikes(x_range, Day, Month, Year)\n",
    "            table = [(plot*overlay).relabel(iccid) for plot,iccid in zip(table,iccids)]    \n",
    "\n",
    "    else:\n",
    "        overlay = dummy_spikes(x_range, Day, Month, Year)\n",
    "        table = [(plot*overlay).relabel(iccid) for plot,iccid in zip(table,iccids)]    \n",
    "\n",
    "        \n",
    "    return  hv.Layout(table).cols(1)\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "#changes the html object when another column is selected, it si not possible to draw to same graph with different axes\n",
    "def render(obj):\n",
    "    renderer = hv.renderer('bokeh')\n",
    "    plot = renderer.get_plot(obj)\n",
    "    size = renderer.get_size(plot)\n",
    "    #return renderer.figure_data(plot), size #bokeh older than 0.12.10 and holoview older than 1.9.0\n",
    "    return renderer._figure_data(plot), size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DateExplorer(hv.streams.Stream):\n",
    "    \n",
    "    output = paramnb.view.HTML(renderer=render)\n",
    "    \n",
    "    Node = param.ObjectSelector(default='582', objects=nodes_for_table()['ping'], precedence=5)\n",
    "    \n",
    "    Day = param.ObjectSelector(default='01', objects=[\"%.2d\" % i for i in range(1,32)], precedence=1)\n",
    "    Month = param.ObjectSelector(default='01', objects=[\"%.2d\" % i for i in range(1,13)],precedence=2)\n",
    "\n",
    "    \n",
    "    #Month = param.Integer(default=10, bounds=(1, 12),precedence=2)\n",
    "    Year = param.Integer(default=2018, bounds=(2016, 2018),precedence=3)\n",
    "    Coloring = param.ObjectSelector(default='Frequency', objects=continous+categorical, precedence=4)\n",
    "    Y = param.ObjectSelector(default='RTT', objects=continous, precedence=4)\n",
    "    Colormap = param.ObjectSelector(default=cm['linear_bmy_10_95_c71'], objects=cm.values())\n",
    "    range_stream = RangeX()\n",
    "    \n",
    "    def retData(self):\n",
    "        if self.range_stream.x_range is not None:\n",
    "            return getdf(tables, nodeid=self.Node, start_time=self.range_stream.x_range[0] , end_time=self.range_stream.x_range[1], freq='10ms', tolerance=pd.Timedelta(seconds=600))\n",
    "        else:\n",
    "            return getdf(tables, nodeid=self.Node, start_time='{0}-{1}-{2} 00:00:00'.format(self.Year, self.Month, self.Day), end_time='{0}-{1}-{2} 23:59:59'.format(self.Year, self.Month, self.Day), \n",
    "                         freq='10ms', tolerance=pd.Timedelta(seconds=600))\n",
    "            \n",
    "        \n",
    "    \n",
    "    def event(self, **kwargs):\n",
    "        if self.output is None or 'Day' in kwargs or 'Month' in kwargs or 'Year' in kwargs or 'Node' in kwargs  or 'Coloring' in kwargs  or 'Y' in kwargs or 'Colormap' in kwargs:\n",
    "                      #or 'Colormap' in kwargs\n",
    "            if 'Day' in kwargs or 'Month' in kwargs or 'Year':\n",
    "                self.range_stream=RangeX()\n",
    "                \n",
    "            self.output = hv.DynamicMap(hv.Callable(load_data, stream_mapping={0: [self.range_stream]}), streams=[self, self.range_stream])\n",
    "            \n",
    "\n",
    "        else:            \n",
    "            super(DateExplorer, self).event( **kwargs)\n",
    "\n",
    "class Plot(object):\n",
    "    def __init__(self): \n",
    "        self.explorer = DateExplorer()\n",
    "        paramnb.Widgets(self.explorer, continuous_update=True, callback=self.explorer.event, on_init=True)\n",
    "    def retData(self):\n",
    "        return self.explorer.retData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation initalisation and interaction\n",
    "Running the cell below should produce a node/date/parameter selector and plots of these for all of the node's interfaces.\n",
    "If you want to visualise data from multiple nodes simultaneously, simply copy the cell, rename the variable (say to ```plot2```) and run it.\n",
    "\n",
    "### Interactive visualisation\n",
    "The visualisation widget allows the user to:\n",
    "* Select the date (day, month, year) for which the data will be shown. \n",
    "* Select the node whose data will be visualised.\n",
    "* Select the parameter that will be shown on the Y axis.\n",
    "* Select the parameter that will correspond to the coloring of the plotted points. \n",
    "* Select the colormap.\n",
    "\n",
    "The data is initially always shown on a 24-hour plot and for all interfaces on the selected node (plot title corresponds to the interface ICCID). However, the user can zoom in to a particular region on the plot, in which case all plots are zoomed in simultaneously.\n",
    "\n",
    "The time series plot by default shows experiment start/stop/deployed/deploying times, as user experiment may impact metadata readings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Running this cell should produce a node/date/parameter selector and the corresponding plots\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "plot1 = Plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection and storage\n",
    "Data can be selected with Lasso select or Box select on a plot. \n",
    "Calling ```retData()``` function of the ```Plot``` object returns a data frame that corresponds to the selected data as in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Returns a dataframe that is held in df_selected object\n",
    "df_selected = plot1.retData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#find column cerrlation why RTT changed, growth=True => why it raised, growth=False => why lowered, middle is where set is divided\n",
    "from ricercando.significance import (hyper_test)\n",
    "def test_columns (df, growth=True, middle=-5000):\n",
    "    result = []\n",
    "    \n",
    "    for iccid,group in df.groupby('Iccid'):\n",
    "        if middle==-5000:\n",
    "            median = group['RTT'].median()\n",
    "        else:\n",
    "            median=middle\n",
    "        if growth:\n",
    "            rtt_ok = group.apply(lambda row: True if row['RTT'] > median  else False, axis=1)\n",
    "        else:\n",
    "            rtt_ok = group.apply(lambda row: True if row['RTT'] < median  else False, axis=1)\n",
    "        for col in [g for g in group.columns if g not in['RTT', 'NodeID', 'Iccid', 'MCC_MNC', 'Interface', 'Error']]:\n",
    "            temp = hyper_test(group[col], rtt_ok).reset_index()\n",
    "            if not temp.empty:\n",
    "                temp.rename( columns={temp.columns[0]: 'Variable'}, inplace=True)\n",
    "                temp['Variable'] = temp.apply(lambda row: iccid+','+col+'='+str(row['Variable'][0]), axis=1)\n",
    "                result.append(temp)\n",
    "    temp = pd.concat(result).sort_values(by='enrichment', ascending=False)\n",
    "    temp = temp[temp['count']>400]\n",
    "#     return temp[temp['p-value']<=0.2]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#find out why RTT has spiked\n",
    "test_columns (plot1.retData())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected data can now be stored on a local disk and loaded in Orange using the iPython connector widget from the MONROE toolbox. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stores the df_selected dataframe to a local disk.\n",
    "%store df_selected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
